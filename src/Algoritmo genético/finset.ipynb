{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1 - Recolha de tweets com cashtag $AAPL \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas \n",
    "\n",
    "from emoji import UNICODE_EMOJI\n",
    "import nltk                                # Python library for NLP\n",
    "from nltk.corpus import twitter_samples    # sample Twitter dataset from NLTK\n",
    "from collections import Counter\n",
    "\n",
    "# import SentimentIntensityAnalyzer class\n",
    "# from vaderSentiment.vaderSentiment module.\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "def is_emoji(s):\n",
    "    count = 0\n",
    "    for emoji in UNICODE_EMOJI['en']:\n",
    "        count += s.count(emoji)\n",
    "    return count\n",
    "\n",
    "def listToString(s): \n",
    "    \n",
    "    # initialize an empty string\n",
    "    str1 = \" \" \n",
    "    \n",
    "    # return string  \n",
    "    return (str1.join(s))\n",
    "\n",
    "\n",
    "################# tweets samples #########################\n",
    "nltk.download('twitter_samples')\n",
    "                \n",
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "###################### POSITIVE WORDS ####################\n",
    "\n",
    "list_pos = []\n",
    "for x in all_positive_tweets:\n",
    "    x = \" \".join(filter(lambda x:x[0]!='@', x.split()))\n",
    "    for i in x.split():\n",
    "        list_pos.append(i)\n",
    "##### Extra https://ptrckprry.com/course/ssd/data/positive-words.txt ##\n",
    "with open('pos_words.txt', 'r') as f:\n",
    "    myNames = [line.strip() for line in f]\n",
    "\n",
    "list_pos.extend(myNames)\n",
    "print(len(list_pos))\n",
    "#########################################################\n",
    "##################### NEGATIVE WORDS ###################\n",
    "list_neg = []\n",
    "for x in all_negative_tweets:\n",
    "    x = \" \".join(filter(lambda x:x[0]!='@', x.split()))\n",
    "    for i in x.split():\n",
    "        list_neg.append(i)\n",
    "##### Extra https://ptrckprry.com/course/ssd/data/negative-words.txt ##\n",
    "with open('neg_words.txt', 'r') as f:\n",
    "    myNames = [line.strip() for line in f]\n",
    "\n",
    "list_neg.extend(myNames)\n",
    "print(len(list_neg))\n",
    "########################################################\n",
    "# Creating list to append tweet data to\n",
    "tweets_list = []\n",
    "def get_tweets():\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper('$AAPL until:2022-02-12 since:2022-01-28 lang:en').get_items()):\n",
    "        if \"$AAPL\" in tweet.content: \n",
    "           #remove urls\n",
    "            regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "            url = re.findall(regex,tweet.content)\n",
    "            #remove emojis\n",
    "            #print(is_emoji(tweet.content))\n",
    "            #remove urls and emojis\n",
    "            if url == [] and is_emoji(tweet.content) == 0:\n",
    "\n",
    "                ####################### Pré-processamento ##################################\n",
    "                # remove special characters\n",
    "                tweet.content = \" \".join(filter(lambda x:x[0]!='$', tweet.content.split()))\n",
    "                tweet.content = re.sub(r\"[^a-zA-Z0-9]+\", ' ', tweet.content)\n",
    "                tweet.content.lower()\n",
    "\n",
    "                #remove \\n and \\t\n",
    "                tweet_words_list = tweet.content.split(\" \")\n",
    "                tweet_new_list = []\n",
    "                for word in tweet_words_list:\n",
    "                    list_word = word.split(\"\\n\")\n",
    "                    word = listToString(list_word)\n",
    "                    word = word.strip('\\n')\n",
    "                    word = word.strip('\\t')\n",
    "                    tweet_new_list.append(word)\n",
    "                tweet.content = listToString(tweet_new_list)\n",
    "\n",
    "                ######################## Número de palavras ################################\n",
    "                pos_count_tweet = 0\n",
    "                neg_count_tweet = 0\n",
    "                total_count_tweet = 0\n",
    "                for word in tweet.content.split():\n",
    "                    sid_obj_word = SentimentIntensityAnalyzer()\n",
    "                    sentiment_dict_word = sid_obj_word.polarity_scores(word)\n",
    "                    if sentiment_dict_word['compound'] >= 0.05:\n",
    "                        pos_count_tweet += 1\n",
    "                        total_count_tweet += 1\n",
    "                    elif sentiment_dict_word['compound'] <= -0.05:\n",
    "                        neg_count_tweet += 1\n",
    "                        total_count_tweet += 1\n",
    "                    else:\n",
    "                        total_count_tweet += 1\n",
    "\n",
    "                #print(pos_count_tweet, neg_count_tweet, total_count_tweet)\n",
    "                ####################### Polarity ###########################################\n",
    "                #polarity = functions.get_tweet_sentiment(tweet.content) textblob\n",
    "                sid_obj = SentimentIntensityAnalyzer()\n",
    " \n",
    "\n",
    "                sentiment_dict = sid_obj.polarity_scores(tweet.content)\n",
    "     \n",
    "\n",
    "                polarity = sentiment_dict['compound']\n",
    "    \n",
    "                if polarity >= 0.05:\n",
    "                    tweets_list.append([tweet.username, tweet.date, tweet.content, pos_count_tweet, neg_count_tweet, total_count_tweet, polarity, \"Positivo\"])\n",
    "                \n",
    "                elif polarity <= -0.05:\n",
    "                    tweets_list.append([tweet.username, tweet.date, tweet.content, pos_count_tweet, neg_count_tweet, total_count_tweet, polarity, \"Negativo\"])\n",
    "                else:\n",
    "                    \n",
    "                    tweets_list.append([tweet.username, tweet.date, tweet.content, pos_count_tweet, neg_count_tweet, total_count_tweet, polarity, \"Neutro\"])\n",
    "\n",
    "\n",
    "get_tweets()\n",
    "\n",
    "# Creating a dataframe from the tweets list above \n",
    "tweets_df1 = pd.DataFrame(tweets_list, columns=['User','Datetime', 'Text', 'Pos_Count', 'Neg_Count', 'Total of word', 'Polarity_count', 'Polarity'])\n",
    "tweets_df1.to_csv('srcrape_tweets_vader_neutro_clean_12_02_28_02.csv')\n",
    "print(tweets_df1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3 - Recolha das informações sobre o utilizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### TWEEPY ############################\n",
    "import tweepy\n",
    "\n",
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "from datetime import date\n",
    "\n",
    "#########################################################\n",
    "consumer_key = \"XXXXXXX\"\n",
    "consumer_secret = \"XXXXXXXX\"\n",
    "access_token = \"XXXXXXXXX\"\n",
    "access_token_secret = \"XXXXXXXXXX\"\n",
    "\n",
    "################## LIST OF USERS ########################\n",
    "# extract a column from cvs file and convert to string\n",
    "\n",
    "data_12_02 = pd.read_csv('srcrape_tweets_vader_neutro_clean_12_02_28_02.csv')\n",
    "data_12_01 = pd.read_csv('srcrape_tweets_vader_neutro_clean_12_01_27_01.csv')\n",
    "info_users = pd.read_csv('srcrape_tweets_user_information_2.csv')\n",
    "user_info_list = info_users['User'].tolist()\n",
    "#print(user_info_list)\n",
    "list_data_1 = data_12_01.to_numpy().tolist()\n",
    "list_data_2 = data_12_01.to_numpy().tolist()\n",
    "#converting column data to list\n",
    "user_name_list_not_clean = data_12_02['User'].tolist()\n",
    "#print(user_name_list_not_clean)\n",
    "user_name_list_not_clean.extend(data_12_01['User'].tolist())\n",
    "\n",
    "\n",
    "user_list_cleanm = []\n",
    "user_name_list_clean  = list(dict.fromkeys(user_name_list_not_clean))\n",
    "print(len(user_name_list_clean))\n",
    "for name in user_name_list_clean:\n",
    "    if name  not in user_info_list:\n",
    "       user_list_cleanm.append(name)\n",
    "\n",
    "users_list_info = []\n",
    "print(f\"Number of total users: {len(user_name_list_clean)}\")\n",
    "#########################################################\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "  \n",
    "# set access to user's access key and access secret \n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "  \n",
    "# calling the api \n",
    "todays_date = date.today()\n",
    "api = tweepy.API(auth)\n",
    "################## USER DATA#############################\n",
    "count = 0\n",
    "for screen_name in user_list_cleanm:\n",
    "    user_tweets_i = []\n",
    "    # fetching the user\n",
    "    \n",
    "    if api.get_user(screen_name=screen_name):\n",
    "        user = api.get_user(screen_name=screen_name)\n",
    "    \n",
    "    \n",
    "    # fetching the user\n",
    "        \n",
    "        #Number of Followers:\n",
    "        # fetching the followers_count\n",
    "        followers_count = user.followers_count\n",
    "\n",
    "        #2) Number of Tweets:\n",
    "        statuses_count = user.statuses_count \n",
    "\n",
    "        #3) Number of retweets and favorites\n",
    "        \n",
    "        #5) Number of Public Lists:\n",
    "        listed_count = user.listed_count\n",
    "\n",
    "        #6) Actions to Tweets Ratio: \n",
    "        #retweet_count = tweet.retweet_count\n",
    "        #favorite_count = tweet.favorite_count\n",
    "        #favourites_count = user.favourites_count\n",
    "        \n",
    "        #11) New Tweets:  dentro do periodo indicado\n",
    "\n",
    "        # retweets += tweet.retweet_count\n",
    "            #favorites += tweet.favorite_count\n",
    "        #action_ratio = (retweet_count + favorite_count) / statuses_count\n",
    "\n",
    "        #7) Followers to Friend Ratio: \n",
    "        friends_count = user.friends_count\n",
    "        print(f\"Friends count: {friends_count} for {screen_name}\")\n",
    "        if friends_count > 0:\n",
    "            followers_friend_ratio = followers_count / friends_count\n",
    "        else:\n",
    "            followers_friend_ratio = 0\n",
    "    \n",
    "        #8) Age of Account: \n",
    "        \n",
    "        created_at = user.created_at\n",
    "        date = str(created_at).split()[0]\n",
    "        year = date.split(\"-\")[0]\n",
    "\n",
    "        age_of_account_years = int(todays_date.year) - int(year)\n",
    "    \n",
    "        #9) New Followers:\n",
    "\n",
    "        #10) New Favorites: \n",
    "\n",
    "        #11) New Tweets:  dentro do periodo indicado\n",
    "\n",
    "\n",
    "\n",
    "    # new_tweets_count, new_favorites = get_tweets(api, screen_name)\n",
    "\n",
    "    \n",
    "        for tweet in list_data_1:\n",
    "            if screen_name == tweet[1]:\n",
    "                user_tweets_i.append(tweet)\n",
    "        for tweet in list_data_2:\n",
    "            if screen_name == tweet[1]:\n",
    "                user_tweets_i.append(tweet)\n",
    "\n",
    "\n",
    "        users_list_info.append([screen_name, followers_count, statuses_count,  listed_count,  followers_friend_ratio, age_of_account_years, user_tweets_i])\n",
    "\n",
    "        if count < 400:\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "################# CREATE A DATAFRAME ####################\n",
    "\n",
    "tweets_df1 = pd.DataFrame(users_list_info, columns=['User','Followers', 'Num_Tweets', 'Num_public_lists', 'Followers_friend', 'Age_account'])\n",
    "tweets_df1.to_csv('srcrape_tweets_user_information_tweets.csv')\n",
    "\n",
    "##########################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4 - Aplicação do algoritmo genético"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0            User  Followers  Num_Tweets  Num_public_lists  \\\n",
      "568         568     JonahLupton     556176      147259              5385   \n",
      "615         615  charliebilello     379176       24098              7011   \n",
      "360         360       ripster47     283262       43571              6051   \n",
      "657         657        BigCheds     241363      161446              3662   \n",
      "12           12    MarketRebels     232545       46295              2057   \n",
      "..          ...             ...        ...         ...               ...   \n",
      "227         227      SamiFathi_      10677        8905                93   \n",
      "310         310  Titan_Traders_      10645       19599               117   \n",
      "374         374        iramneek      10071        9975               235   \n",
      "736         736  everytimeicash       9953       43617               237   \n",
      "32           32       dylan522p       9894        3596               275   \n",
      "\n",
      "     Followers_friend  Age_account  \n",
      "568        289.675000           14  \n",
      "615       3159.800000            9  \n",
      "360       3013.425532            4  \n",
      "657       1326.170330           12  \n",
      "12         752.572816            5  \n",
      "..                ...          ...  \n",
      "227         30.593123            2  \n",
      "310        104.362745            2  \n",
      "374          8.234669           13  \n",
      "736         12.456821            8  \n",
      "32          18.738636            4  \n",
      "\n",
      "[80 rows x 7 columns] Empty DataFrame\n",
      "Columns: [Unnamed: 0, User, Followers, Num_Tweets, Num_public_lists, Followers_friend, Age_account]\n",
      "Index: []      Unnamed: 0             User  Followers  Num_Tweets  Num_public_lists  \\\n",
      "133         133  MarketSwingPlay       3073       68971                66   \n",
      "320         320         HShakeee       3060       49037                24   \n",
      "220         220  TRADEPROAcademy       3056        7372                57   \n",
      "140         140      MattBiotech       3045        5807                72   \n",
      "239         239  Harley_murdoch2       3034        9609                 3   \n",
      "..          ...              ...        ...         ...               ...   \n",
      "385         385        DoejiStar       1351        8829                54   \n",
      "782         782     BullishCross       1334        5975                37   \n",
      "452         452        TradeCNBC       1324       38510                29   \n",
      "87           87    Iamlitfitness       1298       18265                 3   \n",
      "683         683       Crypto_mic       1289        1840                13   \n",
      "\n",
      "     Followers_friend  Age_account  \n",
      "133          1.014526            9  \n",
      "320          0.611144           11  \n",
      "220          5.546279           10  \n",
      "140          6.576674            5  \n",
      "239          4.748044            1  \n",
      "..                ...          ...  \n",
      "385          0.857234           10  \n",
      "782          0.000000           11  \n",
      "452          0.289336            7  \n",
      "87           3.011601           11  \n",
      "683         29.295455            4  \n",
      "\n",
      "[80 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "################# Converter de csv para dataframe ########################\n",
    "\n",
    "import pandas as pd \n",
    "#tweets_df1 = pd.DataFrame(users_list_info, columns=['User','Followers', 'Num_Tweets', 'Num_public_lists', 'Followers_friend', 'Age_account'])\n",
    "# making dataframe \n",
    "df = pd.read_csv(\"srcrape_tweets_user_information_2.csv\") \n",
    "############################### SORT ##############################\n",
    "########################## By Followers ###########################\n",
    "\n",
    "df_followers = df.sort_values(by=['Followers'], ascending=False)\n",
    "rank_1 = df_followers.iloc[:40]\n",
    "rank_2 = df_followers.iloc[40:80]\n",
    "rank_3 = df_followers.iloc[80:120]\n",
    "rank_4 = df_followers.iloc[120:160]\n",
    "rank_5 = df_followers.iloc[160:200]\n",
    "rank_6 = df_followers.iloc[200:240]\n",
    "rank_7 = df_followers.iloc[240:280]\n",
    "rank_8 = df_followers.iloc[280:320]\n",
    "rank_9 = df_followers.iloc[320:340]\n",
    "rank_10 = df_followers.iloc[340:380]\n",
    "rank_11 = df_followers.iloc[380:420]\n",
    "rank_12 = df_followers.iloc[420:460]\n",
    "rank_13 = df_followers.iloc[460:500]\n",
    "rank_14 = df_followers.iloc[540:580]\n",
    "rank_15 = df_followers.iloc[580:630]\n",
    "rank_16 = df_followers.iloc[620:660]\n",
    "rank_17 = df_followers.iloc[660:700]\n",
    "rank_18 = df_followers.iloc[700:740]\n",
    "rank_19 = df_followers.iloc[740:780]\n",
    "rank_20 = df_followers.iloc[780:800]\n",
    "\n",
    "###################################################################\n",
    "\n",
    "##########################3 By Num Tweets #########################\n",
    "\n",
    "df_num_tweets = df.sort_values(by=['Num_Tweets'], ascending=False)\n",
    "rank_1 = df_num_tweets.iloc[:40]\n",
    "rank_2 = df_num_tweets.iloc[40:80]\n",
    "rank_3 = df_num_tweets.iloc[80:120]\n",
    "rank_4 = df_num_tweets.iloc[120:160]\n",
    "rank_5 = df_num_tweets.iloc[160:200]\n",
    "rank_6 = df_num_tweets.iloc[200:240]\n",
    "rank_7 = df_num_tweets.iloc[240:280]\n",
    "rank_8 = df_num_tweets.iloc[280:320]\n",
    "rank_9 = df_num_tweets.iloc[320:340]\n",
    "rank_10 = df_num_tweets.iloc[340:380]\n",
    "rank_11 = df_num_tweets.iloc[380:420]\n",
    "rank_12 = df_num_tweets.iloc[420:460]\n",
    "rank_13 = df_num_tweets.iloc[460:500]\n",
    "rank_14 = df_num_tweets.iloc[540:580]\n",
    "rank_15 = df_num_tweets.iloc[580:630]\n",
    "rank_16 = df_num_tweets.iloc[620:660]\n",
    "rank_17 = df_num_tweets.iloc[660:700]\n",
    "rank_18 = df_num_tweets.iloc[700:740]\n",
    "rank_19 = df_num_tweets.iloc[740:780]\n",
    "rank_20 = df_num_tweets.iloc[780:800]\n",
    "\n",
    "\n",
    "###################################################################\n",
    "\n",
    "##########################3 By Num_public_lists ###################\n",
    "df_num_public_lists = df.sort_values(by=['Num_public_lists'], ascending=False)\n",
    "\n",
    "rank_1 = df_num_public_lists.iloc[:40]\n",
    "rank_2 = df_num_public_lists.iloc[40:80]\n",
    "rank_3 = df_num_public_lists.iloc[80:120]\n",
    "rank_4 = df_num_public_lists.iloc[120:160]\n",
    "rank_5 = df_num_public_lists.iloc[160:200]\n",
    "rank_6 = df_num_public_lists.iloc[200:240]\n",
    "rank_7 = df_num_public_lists.iloc[240:280]\n",
    "rank_8 = df_num_public_lists.iloc[280:320]\n",
    "rank_9 = df_num_public_lists.iloc[320:340]\n",
    "rank_10 = df_num_public_lists.iloc[340:380]\n",
    "rank_11 = df_num_public_lists.iloc[380:420]\n",
    "rank_12 = df_num_public_lists.iloc[420:460]\n",
    "rank_13 = df_num_public_lists.iloc[460:500]\n",
    "rank_14 = df_num_public_lists.iloc[540:580]\n",
    "rank_15 = df_num_public_lists.iloc[580:630]\n",
    "rank_16 = df_num_public_lists.iloc[620:660]\n",
    "rank_17 = df_num_public_lists.iloc[660:700]\n",
    "rank_18 = df_num_public_lists.iloc[700:740]\n",
    "rank_19 = df_num_public_lists.iloc[740:780]\n",
    "rank_20 = df_num_public_lists.iloc[780:800]\n",
    "\n",
    "###################################################################\n",
    "\n",
    "##########################3 By Followers_friend ##################\n",
    "df_racio = df.sort_values(by=['Followers_friend'], ascending=False)\n",
    "#print(df_racio)\n",
    "\n",
    "rank_1 = df_racio.iloc[:40]\n",
    "rank_2 = df_racio.iloc[40:80]\n",
    "rank_3 = df_racio.iloc[80:120]\n",
    "rank_4 = df_racio.iloc[120:160]\n",
    "rank_5 = df_racio.iloc[160:200]\n",
    "rank_6 = df_racio.iloc[200:240]\n",
    "rank_7 = df_racio.iloc[240:280]\n",
    "rank_8 = df_racio.iloc[280:320]\n",
    "rank_9 = df_racio.iloc[320:340]\n",
    "rank_10 = df_racio.iloc[340:380]\n",
    "rank_11 = df_racio.iloc[380:420]\n",
    "rank_12 = df_racio.iloc[420:460]\n",
    "rank_13 = df_racio.iloc[460:500]\n",
    "rank_14 = df_racio.iloc[540:580]\n",
    "rank_15 = df_racio.iloc[580:630]\n",
    "rank_16 = df_racio.iloc[620:660]\n",
    "rank_17 = df_racio.iloc[660:700]\n",
    "rank_18 = df_racio.iloc[700:740]\n",
    "rank_19 = df_racio.iloc[740:780]\n",
    "rank_20 = df_racio.iloc[780:800]\n",
    "\n",
    "\n",
    "###################################################################\n",
    "\n",
    "##########################3 By Age_account #########################\n",
    "df_age = df.sort_values(by=['Age_account'], ascending=False)\n",
    "\n",
    "rank_1 = df_age.iloc[:40]\n",
    "rank_2 = df_age.iloc[40:80]\n",
    "rank_3 = df_age.iloc[80:120]\n",
    "rank_4 = df_age.iloc[120:160]\n",
    "rank_5 = df_age.iloc[160:200]\n",
    "rank_6 = df_age.iloc[200:240]\n",
    "rank_7 = df_age.iloc[240:280]\n",
    "rank_8 = df_age.iloc[280:320]\n",
    "rank_9 = df_age.iloc[320:340]\n",
    "rank_10 = df_age.iloc[340:380]\n",
    "rank_11 = df_age.iloc[380:420]\n",
    "rank_12 = df_age.iloc[420:460]\n",
    "rank_13 = df_age.iloc[460:500]\n",
    "rank_14 = df_age.iloc[540:580]\n",
    "rank_15 = df_age.iloc[580:630]\n",
    "rank_16 = df_age.iloc[620:660]\n",
    "rank_17 = df_age.iloc[660:700]\n",
    "rank_18 = df_age.iloc[700:740]\n",
    "rank_19 = df_age.iloc[740:780]\n",
    "rank_20 = df_age.iloc[780:800]\n",
    "\n",
    "\n",
    "################################## Evaluation Function ##############################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 5 - Yahoo!Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "[['2022-01-13 00:00:00', 74805200.0, 84505800.0, 12.967815071679508], ['2022-01-14 00:00:00', 84505800.0, 80440800.0, -4.810320711714462], ['2022-01-18 00:00:00', 80440800.0, 90956700.0, 13.07284363158994], ['2022-01-19 00:00:00', 90956700.0, 94815000.0, 4.241908512511997], ['2022-01-20 00:00:00', 94815000.0, 91420500.0, -3.580129726309128], ['2022-01-21 00:00:00', 91420500.0, 122848900.0, 34.37784741934249], ['2022-01-24 00:00:00', 122848900.0, 162294600.0, 32.10911941417465], ['2022-01-25 00:00:00', 162294600.0, 115798400.0, -28.64925881699083], ['2022-01-26 00:00:00', 115798400.0, 108275300.0, -6.496721889076188], ['2022-01-27 00:00:00', 108275300.0, 121954600.0, 12.633813990817849], ['2022-01-28 00:00:00', 121954600.0, 179935700.0, 47.543184102936664], ['2022-01-31 00:00:00', 179935700.0, 115541600.0, -35.787284013122466], ['2022-02-01 00:00:00', 115541600.0, 86213900.0, -25.382805846552237], ['2022-02-02 00:00:00', 86213900.0, 84914300.0, -1.5074135377241953], ['2022-02-03 00:00:00', 84914300.0, 89418100.0, 5.303935850616445], ['2022-02-04 00:00:00', 89418100.0, 82465400.0, -7.775495117878818], ['2022-02-07 00:00:00', 82465400.0, 77251200.0, -6.322894207752585], ['2022-02-08 00:00:00', 77251200.0, 74829200.0, -3.135226378360466], ['2022-02-09 00:00:00', 74829200.0, 71285000.0, -4.736386330469924], ['2022-02-10 00:00:00', 71285000.0, 90865900.0, 27.468471627972225], ['2022-02-11 00:00:00', 90865900.0, 98670700.0, 8.589360805318606]]\n"
     ]
    }
   ],
   "source": [
    "from pandas import *\n",
    "import yfinance as yf\n",
    "data = yf.download(\"AAPL\", start='2022-01-12', end='2022-02-12')\n",
    "print(data.columns)\n",
    "\n",
    "############################ DATE ######################\n",
    "\n",
    "data.loc[\"2022-01-12\":\"2022-02-12\"]\n",
    "data.to_excel(\"date.xlsm\")\n",
    "date_df = pd.read_excel('date.xlsm') # can also index sheet by name or fetch all sheets\n",
    "mylist = date_df['Date'].tolist()\n",
    "\n",
    "data_12_02 = pd.read_csv('srcrape_tweets_vader_neutro_clean_12_02_28_02.csv')\n",
    "data_12_01 = pd.read_csv('srcrape_tweets_vader_neutro_clean_12_01_27_01.csv')\n",
    "info_users = pd.read_csv('srcrape_tweets_user_information_2.csv')\n",
    "user_info_list = info_users['User'].tolist()\n",
    "\n",
    "user_tweet_user = []\n",
    "for user in user_info_list:\n",
    "    dt_user = data_12_02.loc[data_12_02['User'] == user]\n",
    "    user_tweet_user.append([user, dt_user])\n",
    "\n",
    "#########################################################\n",
    "\n",
    "\n",
    "list_gain = []\n",
    "list_values = data.values.tolist()\n",
    "\n",
    "\n",
    "gain = 0\n",
    "#print(list_values)\n",
    "for i in range(len(list_values)):\n",
    "    if i == 0:\n",
    "        gain = 0\n",
    "    else:\n",
    "        acp_yesterday = list_values[i-1][5]\n",
    "        acp_today = list_values[i][5]\n",
    "\n",
    "        gain = ((acp_today - acp_yesterday) / (acp_yesterday) )* 100\n",
    "        list_gain.append([str(mylist[i]), acp_yesterday, acp_today, gain])\n",
    "\n",
    "\n",
    "\n",
    "print(list_gain)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2975ce78cb703cbf264356bf7333929784bf3b5ba3576048c471cb2932a2109e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
